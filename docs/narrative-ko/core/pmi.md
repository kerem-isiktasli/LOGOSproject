# PMI (점별 상호정보량) 모듈

> **최종 업데이트**: 2026-01-07
> **코드 위치**: `src/core/pmi.ts`
> **상태**: 활성
> **이론적 기초**: ALGORITHMIC-FOUNDATIONS.md 2부

---

## 맥락 및 목적

### 이 모듈이 존재하는 이유

PMI 모듈은 속이기 쉬운 간단한 질문에 답합니다: **어떤 단어들이 "함께 속하는가"?**

언어 학습에서 연어(자연스럽게 함께 나타나는 단어)를 이해하는 것은 유창하게 들리는 것과 교과서처럼 들리는 것의 차이입니다. 원어민은 "결정을 하다(make a decision)"라고 하지 "결정을 하다(do a decision)"라고 하지 않고, "진한 커피(strong coffee)"라고 하지 "강한 커피(powerful coffee)"라고 하지 않습니다. 이러한 조합은 언어에서 높은 상호정보량을 가지기 때문에 자연스럽게 느껴집니다.

LOGOS는 두 가지 중요한 이유로 이러한 관계를 이해해야 합니다:

1. **어휘 시퀀싱**: "administer"라는 단어를 가르칠 때, LOGOS는 "medication", "test", "treatment"가 의료 영어에서 자연스러운 동반자임을 알아야 합니다. 이것들을 함께 가르치면 더 강한 신경 경로가 만들어집니다.

2. **난이도 예측**: 높은 PMI 단어 쌍은 기억에서 서로를 "점화"하기 때문에 회상하기 더 쉽습니다. "patient history"라는 구는 "patient paradigm"보다 쉽습니다. 전자는 강한 연어이고 후자는 어색하게 느껴지기 때문입니다.

---

## 핵심 통찰: 통계적 연관

### PMI가 실제로 측정하는 것

PMI는 답합니다: "이 두 단어를 함께 보게 되면 얼마나 놀라야 하는가?"

공식은 우아합니다:

```
PMI(w1, w2) = log2[ P(w1, w2) / (P(w1) * P(w2)) ]
```

**쉬운 설명**: 단어가 *실제로* 함께 나타나는 빈도와 완전히 독립적이라면 *함께 나타날* 빈도를 비교합니다.

- **PMI > 0**: 단어가 우연보다 더 자주 함께 나타남. 끌림.
- **PMI = 0**: 단어가 우연이 예측하는 대로 정확히 함께 나타남. 관계 없음.
- **PMI < 0**: 단어가 우연보다 덜 함께 나타남. 서로 밀어냄.

### 창 크기가 중요함

모듈은 동시 발생 계산을 위해 구성 가능한 창 크기(기본값: 5단어)를 사용합니다. 이는 모든 것이 모든 것과 동시 발생할 정도로 넓지 않으면서 구 관계를 포착합니다.

이렇게 생각해보세요: "The patient takes medication daily for chronic pain management"라는 문장에서 창이 5일 때:
- "patient"와 "takes"는 동시 발생 (거리 1)
- "patient"와 "medication"은 동시 발생 (거리 2)
- "patient"와 "management"는 동시 발생 안 함 (거리 > 5)

---

## 기술 개념 (쉬운 설명)

### 점별 상호정보량 (PMI)

**기술적**: PMI(x,y) = log2[P(x,y) / (P(x)P(y))]. 결합 확률과 주변 확률의 곱의 로그 비율을 측정합니다.

**쉬운 설명**: 코퍼스에서 거대한 단어 쌍 가방이 있다고 상상해보세요. PMI는 알려줍니다: "무작위로 두 단어를 잡았을 때 예상하는 것보다 이 특정 쌍이 더 많이 또는 덜 나타나고 있는가?" 높은 숫자는 단어가 베스트 프렌드라는 것을 의미합니다. 0은 낯선 사람이라는 것을 의미합니다. 음수는 서로를 적극적으로 피한다는 것을 의미합니다.

### 정규화된 PMI (NPMI)

**기술적**: NPMI = PMI / -log2[P(x,y)]. 결합 이벤트의 자기정보로 나누어 PMI를 [-1, +1] 범위로 정규화합니다.

**쉬운 설명**: 일반 PMI에는 문제가 있습니다: 희귀한 쌍이 희귀하다는 이유만으로 터무니없이 높은 PMI를 가질 수 있습니다. NPMI는 다음과 같이 모든 것을 좋은 -1에서 +1 범위로 스케일링하여 이를 해결합니다:
- +1 = 완벽한 연관 (항상 함께 나타남)
- 0 = 독립 (관계 없음)
- -1 = 완벽한 배제 (절대 함께 나타나지 않음)

### 유의성을 위한 로그 우도 비율 (LLR)

**기술적**: Dunning의 G2 통계량, 2 * sum[관측값 * log(관측값/기대값)]으로 계산됩니다. 자유도 1인 카이제곱 분포를 따릅니다.

**쉬운 설명**: PMI는 연관의 *강도*를 알려주지만, *실제*인지 아니면 그냥 무작위 잡음인지는 알려주지 않습니다. 동전을 10번 던져서 7번 앞면이 나오면 동전이 편향되었나요? 아마 아닐 것입니다, 그냥 분산입니다. 하지만 10,000번 던져서 7,000번 앞면이 나오면 분명히 뭔가 있습니다. LLR은 "이 연관은 우연이 아니라 실제입니다"라고 알려주는 통계 테스트입니다.

**임계 임계값**:
- LLR > 3.84: p < 0.05에서 유의 (`getCollocations()`에서 사용)
- LLR > 6.63: p < 0.01에서 유의
- LLR > 10.83: p < 0.001에서 유의

---

## PMI-IRT 브리지

이것은 아마도 모듈에서 가장 중요한 아키텍처 결정입니다. `pmiToDifficulty()` 함수는 통계적 패턴을 심리측정 매개변수로 변환합니다:

```
높은 PMI (예: +8) --> 낮은 난이도 (예: -1.5)
     강한 연어 = 회상하기 더 쉬움

낮은 PMI (예: +1)  --> 높은 난이도 (예: +1.5)
     약한 연관 = 회상하기 더 어려움
```

**왜 이것이 작동하는가**: 기억 연구에 따르면 강하게 연관된 단어 쌍은 서로를 점화합니다. "strong"을 들으면 "coffee"라는 단어가 이미 뇌에서 부분적으로 활성화됩니다. 이로 인해 인식이 더 빨라지고 회상이 더 쉬워집니다. PMI는 바로 이 연상 강도를 정량화합니다.

---

## FRE 우선순위와의 통합

FRE 우선순위 시스템에는 세 가지 구성요소가 있습니다:
- **F (빈도)**: 이 단어가 얼마나 흔한가?
- **R (관계 밀도)**: 이 단어가 다른 것들과 얼마나 연결되어 있는가?
- **E (맥락적 기여)**: 이 단어가 의미에 얼마나 중요한가?

PMI는 **R**을 직접 공급합니다. 단어의 관계 밀도는 다음에서 계산됩니다:
- 가지고 있는 유의미한 연어의 수 (getCollocations 카운트)
- 그 연어가 얼마나 강한지 (평균 PMI)
- 그 연어가 얼마나 다양한지 (도메인 전반의 분포)

높은-R 단어는 어휘 네트워크에서 "허브" 단어입니다. 이것들을 아는 것이 많은 맥락의 이해를 열어주기 때문에 배우기에 가치가 있습니다.

---

## 과제 유형 수정자

**쉬운 설명**: 단어를 인식하는 것(MCQ)이 회상하는 것(빈칸 채우기)보다 쉽고, 회상하는 것이 생성하는 것(자유 응답)보다 쉽습니다. 두 과제가 같은 PMI를 가진 같은 단어 쌍을 사용하더라도 과제 유형이 효과적인 난이도를 변경합니다.

수정자:
- 인식: -0.5 (더 쉬움, 정답만 찾으면 됨)
- 단서 있는 회상: 0.0 (기준선)
- 단서 없는 회상: +0.5 (더 어려움, 점화해주는 것 없음)
- 생성: +1.0 (가장 어려움, 생성해야 함)
- 시간 제한: +0.3 (시간 압박이 모든 과제에 난이도 추가)

---

## 사용 예시

### 기본 코퍼스 인덱싱 및 PMI 계산

```typescript
import { PMICalculator } from './pmi';

// 창 크기 5로 계산기 생성
const calc = new PMICalculator(5);

// 의료 코퍼스 인덱싱 (토큰화됨)
const tokens = [
  'the', 'patient', 'takes', 'medication', 'daily',
  'for', 'chronic', 'pain', 'management', 'the',
  'patient', 'history', 'reveals', 'prior', 'medication',
  'allergies', 'patient', 'medication', 'compliance', 'is', 'good'
];
calc.indexCorpus(tokens);

// 특정 쌍에 대한 PMI 계산
const result = calc.computePMI('patient', 'medication');
// result: { word1: 'patient', word2: 'medication', pmi: 2.3, npmi: 0.65, ... }
```

### PMI를 IRT 난이도로 변환

```typescript
import { pmiToDifficulty } from './pmi';

// 높은 PMI 연어 = 쉬운 과제
const easyDifficulty = pmiToDifficulty(8, 0.8, 'recognition');
// 약 -1.9 반환 (쉬운 항목)

// 낮은 PMI 쌍 = 어려운 과제
const hardDifficulty = pmiToDifficulty(1, 0.2, 'production');
// 약 +2.1 반환 (어려운 항목)
```

---

## PMI 없이 무엇이 깨지는가

이 모듈이 실패하면:
1. **난이도 보정 실패**: 새 어휘 항목에 원칙적인 난이도 할당이 없음
2. **우선순위 계산 저하**: R 구성요소를 사용할 수 없어 우선순위 정확도가 ~30% 감소
3. **과제 생성 품질 저하**: 오답 선택지가 실수로 연어를 형성하여 학습자를 혼란시킬 수 있음
4. **어휘 시퀀싱이 무작위가 됨**: "함께 속하는" 단어를 그룹화할 방법 없음

---

*이 문서는 다음을 미러링합니다: `src/core/pmi.ts`*

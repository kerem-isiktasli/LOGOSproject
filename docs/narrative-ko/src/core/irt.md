# 문항반응이론 (IRT) 모듈

> **최종 업데이트**: 2026-01-07
> **코드 위치**: `src/core/irt.ts`
> **상태**: 활성

---

## 맥락 및 목적

이 모듈은 **문항반응이론(Item Response Theory)**을 구현합니다 - LOGOS 적응형 학습 시스템의 심리측정학적 백본입니다. IRT를 통해 LOGOS는 학습자의 응답 패턴을 기반으로 얼마나 숙련되었는지 추정하고, 그 기술 수준에 대해 가장 많은 정보를 제공할 항목을 선택할 수 있습니다.

**비즈니스 필요성**: 언어 학습 플랫폼은 개별 학습자에게 적응해야 합니다. IRT 없이는 시스템이 모두에게 같은 항목을 제공하거나(기술 차이 무시) "정답률"과 같은 조잡한 지표에 의존합니다(항목 난이도를 고려하지 않음). IRT는 학습자 능력과 항목 난이도를 같은 척도에 배치하여 현재 기술에 대한 도전 수준의 정밀한 매칭을 가능하게 합니다.

**사용 시점**:
- 모든 학습자 응답 후: Theta(능력)가 재추정됨
- 다음 항목 선택 시: 정보 최대화가 항목 선택을 안내
- 초기 보정 중: 새 어휘에 대한 난이도 매개변수를 설정할 때
- 분석에서: 시간에 따른 학습자의 능력 궤적을 보여줄 때

---

## 미시적 관점: 직접적 관계

### 의존성 (이 파일이 필요로 하는 것)

- **`src/core/types.ts`**:
  - `ItemParameter` - 항목의 속성 (a, b, c 매개변수)
  - `ThetaEstimate` - 표준오차를 포함한 능력 추정치
  - `ItemCalibrationResult` - 항목 보정 출력

### 의존처 (이 파일을 필요로 하는 것)

**핵심 모듈:**
- `src/core/g2p-irt.ts`: IRT를 자소-음소 규칙에 적용
- `src/core/priority.ts`: 우선순위 계산에 theta 추정치 사용
- `src/core/task-matching.ts`: 과제 적합성 평가에 theta 사용
- `src/core/quadrature.ts`: 대안적 EAP 추정 방법 제공

**서비스 계층:**
- `src/main/services/task-generation.service.ts`: 적응형 항목 선택에 `selectNextItem()` 사용
- `src/main/services/scoring-update.service.ts`: 응답 후 `estimateThetaEAP()` 사용
- `src/main/services/state-priority.service.ts`: 대기열 구축에 theta 사용

---

## 거시적 관점: 시스템 통합

### 아키텍처 계층

이 모듈은 핵심 계층의 **순수 알고리즘 코드**입니다:

```
+-----------------------------------------------+
| 렌더러: SessionView, QuestionCard              |
+-----------------------------------------------+
                    |
                    v
+-----------------------------------------------+
| IPC: session.ipc.ts, learning.ipc.ts          |
+-----------------------------------------------+
                    |
                    v
+-----------------------------------------------+
| 서비스: scoring-update, task-generation        |
+-----------------------------------------------+
                    |
                    v
+-----------------------------------------------+
| 핵심: IRT 모듈 (이 파일)                        |  <-- 현재 위치
| 순수 함수, I/O 없음, 부작용 없음                 |
+-----------------------------------------------+
```

### 전체 영향

IRT는 LOGOS의 **개인화 엔진**입니다. 다음을 가능하게 합니다:

| 기능 | IRT가 어떻게 가능하게 하는가 |
|------|----------------------------|
| 적응형 난이도 | 학습자 능력 수준에서 항목 선택 |
| 능력 추적 | Theta 추정치가 시간에 따른 진행을 보여줌 |
| 효율적 학습 | 최대 정보 항목이 낭비된 연습을 최소화 |
| 공정한 평가 | 점수가 항목 난이도를 고려 |
| 보정 | 새 항목이 학습자 응답으로부터 보정됨 |

**IRT 없이는:**
- 모든 학습자가 기술과 관계없이 같은 항목을 받음
- 진행이 원시 정확도로 측정됨 (오해의 소지)
- 어려운 항목이 적절할 때도 "나쁘게" 보임
- 쉬운 항목이 인위적으로 자신감을 부풀림
- 다음에 무엇을 연습할지 선택하는 원칙적 방법이 없음

---

## 알고리즘 설명

### 세 가지 IRT 모델

LOGOS는 복잡성이 증가하는 세 가지 IRT 모델을 구현합니다:

#### 1PL (라쉬 모델)

```
P(정답) = 1 / (1 + e^(-(theta - b)))
```

**쉬운 설명**: 항목을 맞힐 확률은 그것이 당신의 기술(theta)보다 얼마나 더 어려운지(b)에만 의존합니다. 모든 항목은 기술 차이에 대해 동일하게 "민감한" 것으로 가정됩니다.

**사용처**: 변별도가 비교적 균일한 음운 항목.

**예시**: theta가 0(평균)이고 항목 난이도 b가 0(평균)이면, P = 0.5 (50% 확률).

#### 2PL 모델

```
P(정답) = 1 / (1 + e^(-a(theta - b)))
```

**쉬운 설명**: 1PL과 같지만 항목이 다른 "날카로움"(a)을 가질 수 있습니다. 높은-a 항목은 숙련된 학습자와 미숙련 학습자를 날카롭게 구별합니다; 낮은-a 항목은 기술과 관계없이 비슷한 결과를 줍니다.

**사용처**: 변별도가 다양한 어휘 및 통사 항목.

**a가 중요한 이유**:
- a = 2.0: 가파른 곡선 - 작은 기술 차이가 큰 확률 변화를 유발
- a = 0.5: 완만한 곡선 - 큰 기술 차이도 작은 확률 변화만 보임

#### 3PL 모델

```
P(정답) = c + (1-c) / (1 + e^(-a(theta - b)))
```

**쉬운 설명**: 2PL과 같지만 추측을 고려합니다. 매우 낮은 기술의 사람도 때때로 올바르게 추측할 수 있습니다. 매개변수 c는 추측 하한입니다.

**사용처**: 추측이 가능한 화용 항목 및 선다형 문제.

**c가 중요한 이유**: 4지선다형 MCQ에서 무작위 추측도 25% 정답을 줍니다. 3PL 모델은 운 좋은 추측에 대해 저능력 학습자에게 불이익을 주지 않습니다.

### Theta 추정 방법

#### 최대우도추정 (MLE)

**하는 일**: 관찰된 응답 패턴을 가장 가능하게 만드는 theta 값을 찾습니다.

**작동 방식**:
1. theta = 0으로 시작
2. 우도 함수의 기울기(그래디언트) 계산
3. 더 가파른 우도 방향으로 뉴턴-랩슨 단계 취함
4. 수렴할 때까지 반복

**장점**:
- 불편 추정치 (평균적으로 정확)
- 효율적 (불편 추정량 중 최소 분산)

**단점**:
- 극단적 패턴에서 발산 (모두 정답 또는 모두 오답)
- 안정하려면 여러 응답 필요

**사용 시점**: 혼합된 결과를 가진 5개 이상의 응답이 있을 때.

#### 사후기대값 (EAP)

**하는 일**: 응답과 사전 신념이 주어졌을 때 theta의 사후 분포의 평균을 계산합니다.

**작동 방식**:
1. 사전 분포 정의 (일반적으로 정규분포, 평균=0, SD=1)
2. 많은 theta 값에서 사전과 우도를 곱함 (구적법)
3. 정규화하여 사후 분포 얻음
4. 사후의 평균 반환

**장점**:
- 항상 유한 (절대 발산하지 않음)
- 사전 지식 통합
- 적은 응답에서 안정적

**단점**:
- 사전 쪽으로 편향 (축소)
- 더 계산 집약적

**사용 시점**: 항상, 특히 학습 초기나 극단적 패턴에서. LOGOS는 EAP를 기본으로 사용합니다.

### 항목 선택 전략

#### Fisher 정보 최대화

**하는 일**: theta에 대한 불확실성을 가장 많이 줄일 항목을 선택합니다.

**작동 방식**:
1. 각 후보 항목에 대해 현재 theta에서 Fisher 정보 계산
2. Fisher Info = a^2 * P * (1-P)
3. 최대 정보를 가진 항목 선택

**쉬운 설명**: 성공이 가장 불확실한 항목을 선택합니다 (P가 0.5에 가까운). 거기서 학습자의 진정한 능력에 대해 가장 많이 배웁니다.

**정보 최대화 곡선**:
```
정보
     |
     |        *****
     |      **     **
     |    **         **
     |  **             **
     | *                 *
     |*                   *
     +-------------------------> Theta
        (theta = b일 때)
```

최대 정보는 theta가 난이도(b)와 같을 때 발생합니다.

---

## 기술 개념 (쉬운 설명)

### 로짓 척도

**기술적**: logit(p) = ln(p/(1-p))인 로그 승산 변환으로, 확률 (0,1)을 (-inf, +inf)에 매핑합니다.

**쉬운 설명**: "75% 확률"이라고 말하는 대신 logit = 1.1이라고 말합니다. "50%" 대신 logit = 0이라고 말합니다. 로짓 척도는 수학이 잘 작동하게 하고 능력과 난이도를 비교하는 자연스러운 방법을 제공합니다.

**사용하는 이유**: 로짓 척도에서 차이는 의미가 있습니다. Theta 1.0 vs 2.0은 2.0 vs 3.0과 같은 기술 격차를 의미합니다. 원시 확률에서는 그렇지 않습니다 (75% vs 88%는 88% vs 97%와 같은 격차가 아닙니다).

### 표준오차 (SE)

**기술적**: theta 추정치의 표본 분포의 추정 표준편차.

**쉬운 설명**: 추정치에 대한 확신 정도. SE = 0.3은 꽤 확신함을 의미합니다 (theta ± 0.6이 95%를 커버). SE = 1.5는 매우 불확실함을 의미합니다.

**사용하는 이유**: SE는 언제 추정치를 신뢰할지 알려줍니다. 학습 초기에 SE는 높습니다 - 더 많은 데이터가 필요합니다. 많은 응답 후에 SE는 줄어듭니다 - 학습자를 잘 알게 됩니다.

### 변별도 (a 매개변수)

**기술적**: 변곡점에서 항목 특성 곡선(ICC)의 기울기로, 능력과 성공 확률 간의 관계를 결정합니다.

**쉬운 설명**: 항목이 얼마나 "진단적"인지. 높은-a 항목은 날카로운 진단 테스트와 같습니다 - 숙련과 미숙련을 명확히 분리합니다. 낮은-a 항목은 노이즈 많은 측정과 같습니다 - 기술 수준이 결과에 거의 영향을 미치지 않습니다.

### 추측 매개변수 (c)

**기술적**: ICC의 하한 점근선으로, 무한히 낮은 능력을 가진 수험자의 정답 확률을 나타냅니다.

**쉬운 설명**: 추측의 하한. 4지선다형 MCQ에서 완전 초보자도 25%의 시간에 올바르게 추측합니다. c 매개변수는 모델이 운 좋은 추측에 속지 않도록 합니다.

---

## 구현 참고사항

### 수치적 안정성

모듈은 여러 안전장치를 포함합니다:

1. **클램핑된 매개변수**: a는 [0.2, 3.0], b는 [-4.0, 4.0]으로 제한
2. **나눗셈 가드**: L2 (헤시안)는 나눗셈 전에 0인지 확인
3. **우도 하한**: 로그 우도는 log(0)을 피하기 위해 epsilon 사용
4. **수렴 제한**: 최대 50회 반복으로 무한 루프 방지

### 성능 특성

| 함수 | 복잡도 | 일반적 시간 |
|------|--------|-------------|
| probability2PL | O(1) | < 1ms |
| estimateThetaMLE | O(n * iterations) | 50개 항목에 < 5ms |
| estimateThetaEAP | O(n * quadPoints) | 41개 점에 < 10ms |
| selectNextItem | O(n) 항목 | < 1ms |
| calibrateItems | O(n * m * iterations) | 100-500ms |

여기서 n = 항목, m = 사람.

---

## 학술적 참고문헌

- 1PL, 2PL, 3PL 확률 함수는 기초적임
- 뉴턴-랩슨 MLE는 표준 심리측정 관행을 따름
- 가우시안 구적법을 사용한 EAP는 Bock & Mislevy (1982)를 따름
- KL 발산 선택은 Chang & Ying (1996)을 따름
- EM 보정은 Bock & Aitkin (1981)을 따름
